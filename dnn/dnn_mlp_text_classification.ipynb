{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Redes Neurais Profundas\n",
        "\n",
        "Uma rede neural profunda do tipo Feed Forward Multilayer Perceptron para classificação de tweets na polaridade positiva, negativa e neutra.\n"
      ],
      "metadata": {
        "id": "DAsprD5a24oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "2AM1-sRZjlb1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GoQCbKb4jOV3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return self.softmax(x)"
      ],
      "metadata": {
        "id": "_Gp4Lr943K-S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregar dados do arquivo CSV usando pandas"
      ],
      "metadata": {
        "id": "h59mNYZd3V2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('https://raw.githubusercontent.com/giacicunb/enap_pln2024/main/corpora/twitter-2016train-A.txt',sep='\\t',encoding=\"UTF-8\")\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/giacicunb/enap_pln2024/main/corpora/twitter-2016test-A.txt',sep='\\t',encoding=\"UTF-8\")"
      ],
      "metadata": {
        "id": "e6qaY3l23UzB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Número de classes (são 3 tipos de polaridade de tweets)"
      ],
      "metadata": {
        "id": "ZLhvcj9t6LtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(df_train['polarity'].unique())"
      ],
      "metadata": {
        "id": "XYkeZihE6L0_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtém os tweets e as labels separadamente para os dados de treinamento e de teste"
      ],
      "metadata": {
        "id": "vWiUABFD3so4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['polarity'] = pd.Categorical(df_train['polarity'])\n",
        "df_train['polarity'] = df_train['polarity'].cat.codes\n",
        "\n",
        "df_test['polarity'] = pd.Categorical(df_test['polarity'])\n",
        "df_test['polarity'] = df_test['polarity'].cat.codes\n",
        "\n",
        "train_tweets = df_train['text'].tolist()\n",
        "train_labels = df_train['polarity'].tolist()\n",
        "\n",
        "test_tweets = df_test['text'].tolist()\n",
        "test_labels = df_test['polarity'].tolist()"
      ],
      "metadata": {
        "id": "G_UGLYNG3syv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcula os vetores TF-IDF para os dados de treinamento e de teste"
      ],
      "metadata": {
        "id": "wd3XoZzM4_or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(train_tweets).toarray()\n",
        "\n",
        "test_tfidf = tfidf_vectorizer.transform(test_tweets).toarray()"
      ],
      "metadata": {
        "id": "Mff7-SjU4-Ec"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converter os vetores TF-IDF para tensores"
      ],
      "metadata": {
        "id": "3b1OnEo-5Hbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor = torch.tensor(train_tfidf, dtype=torch.float32)\n",
        "test_tensor = torch.tensor(test_tfidf, dtype=torch.float32)\n",
        "\n",
        "torch_train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "torch_test_labels = torch.tensor(test_labels, dtype=torch.long)"
      ],
      "metadata": {
        "id": "NHXO9Hax5Goj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar instâncias do DataLoader"
      ],
      "metadata": {
        "id": "DsfL2Knh5N-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_tensor, torch_train_labels)\n",
        "test_dataset = CustomDataset(test_tensor, torch_test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "2NzC_laa5OG6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo alguns hiperparâmetros:\n",
        "\n",
        "*   Tamanho do vetor TF-IDF de entrada\n",
        "*   Quantidade de neurônios na camada oculta\n",
        "*   Dimensão da camada de saída\n",
        "\n"
      ],
      "metadata": {
        "id": "blN278rz50Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = train_tensor.shape[1]\n",
        "hidden_size = 128\n",
        "output_size = num_classes"
      ],
      "metadata": {
        "id": "uWNs4Bw43M8B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instancia o objeto referente a rede neural profunda"
      ],
      "metadata": {
        "id": "C9p-zWpM51qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_model = MLPClassifier(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "gvxQXVgB51x4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a função loss e o otimizador de Adam para otimização dos parâmetros"
      ],
      "metadata": {
        "id": "AyUEj22J6U62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(dnn_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "SL9AKkTq6VBu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loop de treinamento do modelo"
      ],
      "metadata": {
        "id": "FVK_ntAm6dm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    dnn_model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for text, labels in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = dnn_model(text)\n",
        "\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2_Tfyow6dwf",
        "outputId": "8f14c134-a74f-44e4-e0c2-23740d94eda0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9853490377083803\n",
            "Epoch 2, Loss: 0.6844639739929101\n",
            "Epoch 3, Loss: 0.24764725470390075\n",
            "Epoch 4, Loss: 0.04763648906149543\n",
            "Epoch 5, Loss: 0.013493162541029355\n",
            "Epoch 6, Loss: 0.005659616397072871\n",
            "Epoch 7, Loss: 0.0028557573864534977\n",
            "Epoch 8, Loss: 0.001659266006661197\n",
            "Epoch 9, Loss: 0.0011676368046140012\n",
            "Epoch 10, Loss: 0.0008304033919837541\n",
            "Epoch 11, Loss: 0.0006240571448683906\n",
            "Epoch 12, Loss: 0.0004702054245101933\n",
            "Epoch 13, Loss: 0.0003707977030456114\n",
            "Epoch 14, Loss: 0.0002939258876535743\n",
            "Epoch 15, Loss: 0.00023848560410372628\n",
            "Epoch 16, Loss: 0.00019609629005292215\n",
            "Epoch 17, Loss: 0.0001610152416665537\n",
            "Epoch 18, Loss: 0.0001359080528438939\n",
            "Epoch 19, Loss: 0.00011437888175490886\n",
            "Epoch 20, Loss: 9.78592943575234e-05\n",
            "Epoch 21, Loss: 8.504011695829552e-05\n",
            "Epoch 22, Loss: 7.082453492283747e-05\n",
            "Epoch 23, Loss: 6.141968662212513e-05\n",
            "Epoch 24, Loss: 5.3908261156137974e-05\n",
            "Epoch 25, Loss: 4.670423230051641e-05\n",
            "Epoch 26, Loss: 4.278225644436763e-05\n",
            "Epoch 27, Loss: 3.65465764214325e-05\n",
            "Epoch 28, Loss: 3.279365307953879e-05\n",
            "Epoch 29, Loss: 2.9676226579165534e-05\n",
            "Epoch 30, Loss: 2.6742048581022223e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A443Os7d8j-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_test = []\n",
        "for text, labels in test_loader:\n",
        "    y_prob = dnn_model(text)\n",
        "    _, predicted = torch.max(y_prob, 1)\n",
        "    y_pred.extend(predicted.tolist())\n",
        "    y_test.extend(labels.tolist())"
      ],
      "metadata": {
        "id": "NVS7IUtk9IaD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RnG0Mrt8kFo",
        "outputId": "f94678eb-78a2-483e-9ee7-af7283802c36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.25      0.27      3231\n",
            "           1       0.56      0.37      0.45     10342\n",
            "           2       0.44      0.68      0.53      7059\n",
            "\n",
            "    accuracy                           0.46     20632\n",
            "   macro avg       0.43      0.43      0.42     20632\n",
            "weighted avg       0.48      0.46      0.45     20632\n",
            "\n"
          ]
        }
      ]
    }
  ]
}