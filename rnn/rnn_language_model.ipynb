{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Redes Neurais Recorrentes\n",
        "\n",
        "Modelo de linguagem baseado em uma rede neural recorrente de Elman.\n",
        "\n",
        "Após o treinamento do modelo em um corpora ()"
      ],
      "metadata": {
        "id": "5yyKo7nqyvUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TGZWUiotN2Ww"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do conjunto de dados"
      ],
      "metadata": {
        "id": "mEJev-qaE87g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.data = pd.read_csv(csv_file,sep='\\t')\n",
        "        self.word_to_idx = {}\n",
        "        self.idx_to_word = {}\n",
        "        self.build_vocab()\n",
        "\n",
        "    def build_vocab(self):\n",
        "        words = ' '.join(self.data['text']).lower()\n",
        "        words = re.sub('['+string.punctuation+']', '', words)\n",
        "        words = words.split()\n",
        "        unique_words = set(words)\n",
        "        self.word_to_idx = {word: idx for idx, word in enumerate(unique_words)}\n",
        "        self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}\n",
        "        novo_idx = len(self.word_to_idx)\n",
        "        self.word_to_idx['<END>'] = novo_idx\n",
        "        self.idx_to_word[novo_idx] = '<END>'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['text']\n",
        "        text = text.lower()\n",
        "        text = re.sub('['+string.punctuation+']', '', text)\n",
        "\n",
        "        tokens = [token for token in text.split() if token != '']\n",
        "        labels = [tokens[i+1] if i < len(tokens)-1 else '<END>' for i in range(len(tokens))]\n",
        "\n",
        "        input_ids = [self.word_to_idx[token] for token in tokens]\n",
        "        label_ids = [self.word_to_idx[label] for label in labels]\n",
        "        return {'input_ids': torch.tensor(input_ids), 'labels': torch.tensor(label_ids)}"
      ],
      "metadata": {
        "id": "Jh5J2GQLE5SR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação da classe relacionada ao modelo RNN"
      ],
      "metadata": {
        "id": "zo27AmGQFGog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, hidden = self.rnn(x)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim)"
      ],
      "metadata": {
        "id": "tT_bKnPUFBU4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparâmetros"
      ],
      "metadata": {
        "id": "1jtDayTpFHqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "QJbBm6-rFDkY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o conjunto de dados"
      ],
      "metadata": {
        "id": "HeVKUvslFXun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset('https://raw.githubusercontent.com/giacicunb/enap_pln2024/main/corpora/simple_corpus.csv')\n",
        "dataloader = DataLoader(dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "r2sCm5BxFX3H"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se está tudo correto com nosso dataset"
      ],
      "metadata": {
        "id": "WTCdIJesg12_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtém-se o tamanho do vocabulário"
      ],
      "metadata": {
        "id": "Sa4i8-vVOrp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(dataset.word_to_idx)\n",
        "print(f'O vocaculario possui {vocab_size} palavras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3JQ4zdfOrxW",
        "outputId": "0430fd02-2cb4-4250-be5e-9a8e0dea8a2f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O vocaculario possui 362 palavras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciando o modelo baseado em RNN"
      ],
      "metadata": {
        "id": "mCyYOsDfFdKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNModel(vocab_size+1, embedding_dim, hidden_dim, num_layers)"
      ],
      "metadata": {
        "id": "CvB2Zw24FdSW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Definindo a função de perda, em que a função softmax está implementada internamente:"
      ],
      "metadata": {
        "id": "SX_T2ji4Film"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Bsr90TBVFiuG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo-se o otimizador Adam"
      ],
      "metadata": {
        "id": "ZGelQn85Ft0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "hJUcGenNFt8u"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento da RNN\n",
        "\n",
        "\n",
        "\n",
        "1.   O treinamento é feito manualmente, pegando-se batch por batch\n",
        "2.   Primeiramente, pega-se os textos do batch sendo analisados e prepara-os para colocá-los no modelo\n",
        "3.   Inicializa $h^{(0)}$\n",
        "4.   Depois, calcula $h^{(t)}$\n",
        "5.   Após processar todas as palavras do texto de entrada, calcula-se a função loss\n",
        "6.   Atualiza os pesos da rede fazendo-se o backpropagation"
      ],
      "metadata": {
        "id": "01jD04pcFQwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "\n",
        "        tokens, labels = batch['input_ids'], batch['labels']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output,_ = model(tokens)\n",
        "\n",
        "        output_flat = output.view(-1, output.shape[-1])\n",
        "        labels_flat = labels.view(-1)\n",
        "\n",
        "        loss = loss_function(output_flat, labels_flat)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4QOsRZtFQ2P",
        "outputId": "04752ae6-56b0-455d-cd7c-c1e81d50ee45"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 5.9012486934661865\n",
            "Epoch 2, Loss: 5.8495674928029375\n",
            "Epoch 3, Loss: 5.806120236714681\n",
            "Epoch 4, Loss: 5.763212601343791\n",
            "Epoch 5, Loss: 5.719970305760701\n",
            "Epoch 6, Loss: 5.675849358240764\n",
            "Epoch 7, Loss: 5.630305528640747\n",
            "Epoch 8, Loss: 5.582701921463013\n",
            "Epoch 9, Loss: 5.532245635986328\n",
            "Epoch 10, Loss: 5.477983395258586\n",
            "Epoch 11, Loss: 5.418991009394328\n",
            "Epoch 12, Loss: 5.355111996332805\n",
            "Epoch 13, Loss: 5.288232723871867\n",
            "Epoch 14, Loss: 5.222163041432698\n",
            "Epoch 15, Loss: 5.159573952356975\n",
            "Epoch 16, Loss: 5.1003719965616865\n",
            "Epoch 17, Loss: 5.043552398681641\n",
            "Epoch 18, Loss: 4.9885936578114825\n",
            "Epoch 19, Loss: 4.9352452754974365\n",
            "Epoch 20, Loss: 4.883035659790039\n",
            "Epoch 21, Loss: 4.831312259038289\n",
            "Epoch 22, Loss: 4.779558340708415\n",
            "Epoch 23, Loss: 4.727481047312419\n",
            "Epoch 24, Loss: 4.67491348584493\n",
            "Epoch 25, Loss: 4.621768395105998\n",
            "Epoch 26, Loss: 4.568012078603108\n",
            "Epoch 27, Loss: 4.513624946276347\n",
            "Epoch 28, Loss: 4.458606680234273\n",
            "Epoch 29, Loss: 4.402997255325317\n",
            "Epoch 30, Loss: 4.3468637863794966\n",
            "Epoch 31, Loss: 4.29027517636617\n",
            "Epoch 32, Loss: 4.233294566472371\n",
            "Epoch 33, Loss: 4.175982276598613\n",
            "Epoch 34, Loss: 4.118402600288391\n",
            "Epoch 35, Loss: 4.060622334480286\n",
            "Epoch 36, Loss: 4.002702991167705\n",
            "Epoch 37, Loss: 3.944698135058085\n",
            "Epoch 38, Loss: 3.886656165122986\n",
            "Epoch 39, Loss: 3.828623652458191\n",
            "Epoch 40, Loss: 3.770644942919413\n",
            "Epoch 41, Loss: 3.712761878967285\n",
            "Epoch 42, Loss: 3.655012369155884\n",
            "Epoch 43, Loss: 3.597432255744934\n",
            "Epoch 44, Loss: 3.5400554736455283\n",
            "Epoch 45, Loss: 3.4829127391179404\n",
            "Epoch 46, Loss: 3.4260329008102417\n",
            "Epoch 47, Loss: 3.3694435755411782\n",
            "Epoch 48, Loss: 3.3131697177886963\n",
            "Epoch 49, Loss: 3.2572360833485923\n",
            "Epoch 50, Loss: 3.2016654014587402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predição"
      ],
      "metadata": {
        "id": "-rByT6SHHNC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, input_text):\n",
        "    input_text = input_text.split()\n",
        "    input_data = torch.tensor([[dataset.word_to_idx[word] for word in input_text]])\n",
        "    output, _ = model(input_data)\n",
        "    _, predicted_idx = torch.max(output[:, -1], 1)\n",
        "    predicted_word = dataset.idx_to_word[predicted_idx.item()]\n",
        "    return predicted_word"
      ],
      "metadata": {
        "id": "lr6EogyyHNKh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo o modelo de linguagem funcionar"
      ],
      "metadata": {
        "id": "guK025axHPmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"termo\"\n",
        "predicted_word = predict_next_word(model, input_text)\n",
        "print(f\"A proxima palavra apos {input_text} eh {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcKk23diHPtp",
        "outputId": "dad7ecf2-5a23-4c87-ba66-f27a3607489b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A proxima palavra apos termo eh europa\n"
          ]
        }
      ]
    }
  ]
}