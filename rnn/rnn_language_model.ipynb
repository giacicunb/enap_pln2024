{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "HzAdt59drBBW"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self,csv_file):\n",
        "        self.data = pd.read_csv(csv_file,sep='\\t')\n",
        "        self.word2index = {}  # palavra : indice (numero inteiro)\n",
        "        self.index2word = {}\n",
        "        self.build_vocab()\n",
        "\n",
        "    def build_vocab(self):\n",
        "        words = ' '.join(self.data['text']).lower()\n",
        "        words = re.sub('['+string.punctuation+']','',words)\n",
        "        words = words.split()\n",
        "        unique_words = set(words) #vocabulario nao pode ter palavras repetidas\n",
        "        self.word2index = {word: index for index, word in enumerate(unique_words)}\n",
        "        self.index2word = {index: word for word,index in self.word2index.items()}\n",
        "        tam = len(self.word2index)\n",
        "        self.word2index[''] = tam\n",
        "        self.index2word[tam] = ''\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # receber um indice, pre-processar a sentenca e retorna-la para onde foi chamada\n",
        "    def __getitem__(self,index):\n",
        "        text = self.data.iloc[index]['text']\n",
        "        text = text.lower()\n",
        "        text = re.sub('['+string.punctuation+']','',text)\n",
        "\n",
        "        tokens = [token for token in text.split() if token != '']\n",
        "        labels = [tokens[i+1] if i < len(tokens)-1 else '' for i in range(0,len(tokens))]\n",
        "\n",
        "        input_ids = [self.word2index[token] for token in tokens]\n",
        "        label_ids = [self.word2index[label] for label in labels]\n",
        "\n",
        "        return {'input_ids' : torch.tensor(input_ids), 'labels_ids' : torch.tensor(label_ids)}"
      ],
      "metadata": {
        "id": "jWBTXlbpq51G"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_dim,num_layers):\n",
        "        super(RNN,self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim,hidden_dim,num_layers,nonlinearity='relu') #dimensao do vetor de palavra, dimensao do estado interno\n",
        "        self.fcl = nn.Linear(hidden_dim,vocab_size)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self,word):\n",
        "        x = self.embedding(word)\n",
        "        output,hidden = self.rnn(x)\n",
        "        output = self.fcl(output)\n",
        "        return output,hidden\n",
        "\n",
        "    def init_hidden(self,batch_size):\n",
        "        torch.zeros(self.num_layers,batch_size,self.hidden_dim)"
      ],
      "metadata": {
        "id": "25qE5Aq3xLWG"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparâmetros"
      ],
      "metadata": {
        "id": "QgIRn4Ob0Fwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "num_layers = 1\n",
        "learning_rate = 0.00001\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "b2VbuLg7z_iF"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "8NPd2rz2qBBj"
      },
      "outputs": [],
      "source": [
        "corpus = CustomDataset('https://raw.githubusercontent.com/giacicunb/enap_pln2024/main/corpora/simple_corpus.csv')\n",
        "dataloader = DataLoader(corpus,batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(corpus.word2index)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8DsBNrV0SUU",
        "outputId": "1f526c8e-b073-4b7a-b72c-f19b3b2af85c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.word2index"
      ],
      "metadata": {
        "id": "ph-q5W6p4hyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_model = RNN(vocab_size,embedding_dim,hidden_dim,num_layers=1)"
      ],
      "metadata": {
        "id": "6zMX06Yy4tJc"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplica implicitamente a função softmax"
      ],
      "metadata": {
        "id": "MOwLRiQ4X1kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "hvFOzt195Lpp"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(language_model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "9tPwE40L5Pp_"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "\n",
        "        tokens,labels = batch['input_ids'],batch['labels_ids']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output,_ = language_model(tokens)\n",
        "\n",
        "        output_flat = output.view(-1,output.shape[-1])\n",
        "        labels_flat = labels.view(-1)\n",
        "\n",
        "        loss = loss_function(output_flat,labels_flat)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1} ======= Loss: {total_loss/len(dataloader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2pvu4Zf5bA1",
        "outputId": "229e8ad7-885d-41e3-92d7-2f70e69a92e1"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ======= Loss: 5.911273797353108\n",
            "Epoch 2 ======= Loss: 5.9078153769175215\n",
            "Epoch 3 ======= Loss: 5.904771010080974\n",
            "Epoch 4 ======= Loss: 5.901766141255696\n",
            "Epoch 5 ======= Loss: 5.89877462387085\n",
            "Epoch 6 ======= Loss: 5.895789861679077\n",
            "Epoch 7 ======= Loss: 5.892809708913167\n",
            "Epoch 8 ======= Loss: 5.889831781387329\n",
            "Epoch 9 ======= Loss: 5.886855840682983\n",
            "Epoch 10 ======= Loss: 5.883881568908691\n",
            "Epoch 11 ======= Loss: 5.880907853444417\n",
            "Epoch 12 ======= Loss: 5.877935886383057\n",
            "Epoch 13 ======= Loss: 5.8749659061431885\n",
            "Epoch 14 ======= Loss: 5.871998071670532\n",
            "Epoch 15 ======= Loss: 5.869032144546509\n",
            "Epoch 16 ======= Loss: 5.866067012151082\n",
            "Epoch 17 ======= Loss: 5.863102515538533\n",
            "Epoch 18 ======= Loss: 5.86013929049174\n",
            "Epoch 19 ======= Loss: 5.857176780700684\n",
            "Epoch 20 ======= Loss: 5.854215701421102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model,input_text):\n",
        "\n",
        "    text = input_text.lower()\n",
        "    text = re.sub('['+string.punctuation+']','',text)\n",
        "    text = text.split()\n",
        "\n",
        "    input_tensor =  torch.tensor([[corpus.word2index[word] for word in text]])\n",
        "\n",
        "    output,_ = model(input_tensor)\n",
        "\n",
        "    prob_value,predicted_index=torch.max(output[:,-1],1)\n",
        "\n",
        "    predicted_word = corpus.index2word[predicted_index.item()]\n",
        "    return predicted_word"
      ],
      "metadata": {
        "id": "FlsmclTA--Hk"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"cacau\"\n",
        "\n",
        "predicted_word = predict_next_word(language_model,input_text)\n",
        "print(f'A proxima palavra apos {input_text} eh {predicted_word}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXRnJGge-ZyG",
        "outputId": "ebcded15-71f2-47b7-980f-1c7d7a8a4c4f"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A proxima palavra apos cacau eh algumas\n"
          ]
        }
      ]
    }
  ]
}