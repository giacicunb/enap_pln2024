{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TGZWUiotN2Ww"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import numpy as np\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do conjunto de dados"
      ],
      "metadata": {
        "id": "mEJev-qaE87g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.data = pd.read_csv(csv_file,sep='\\t')\n",
        "        self.word_to_idx = {}\n",
        "        self.idx_to_word = {}\n",
        "        self.build_vocab()\n",
        "\n",
        "    def build_vocab(self):\n",
        "        words = ' '.join(self.data['text']).lower()\n",
        "        words = re.sub('['+string.punctuation+']', '', words)\n",
        "        words = words.split()\n",
        "        unique_words = set(words)\n",
        "        self.word_to_idx = {word: idx for idx, word in enumerate(unique_words)}\n",
        "        self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}\n",
        "        novo_idx = len(self.word_to_idx)\n",
        "        self.word_to_idx['<END>'] = novo_idx\n",
        "        self.idx_to_word[novo_idx] = '<END>'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['text']\n",
        "        text = text.lower()\n",
        "        text = re.sub('['+string.punctuation+']', '', text)\n",
        "\n",
        "        tokens = [token for token in text.split() if token != '']\n",
        "        labels = [tokens[i+1] if i < len(tokens)-1 else '<END>' for i in range(len(tokens))]\n",
        "\n",
        "        input_ids = [self.word_to_idx[token] for token in tokens]\n",
        "        label_ids = [self.word_to_idx[label] for label in labels]\n",
        "        return {'input_ids': torch.tensor(input_ids), 'labels': torch.tensor(label_ids)}"
      ],
      "metadata": {
        "id": "Jh5J2GQLE5SR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação da classe relacionada ao modelo RNN"
      ],
      "metadata": {
        "id": "zo27AmGQFGog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, hidden = self.rnn(x)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim)"
      ],
      "metadata": {
        "id": "tT_bKnPUFBU4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparâmetros"
      ],
      "metadata": {
        "id": "1jtDayTpFHqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "QJbBm6-rFDkY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o conjunto de dados"
      ],
      "metadata": {
        "id": "HeVKUvslFXun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset('https://raw.githubusercontent.com/giacicunb/enap_pln2024/main/corpora/simple_corpus.csv')\n",
        "dataloader = DataLoader(dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "r2sCm5BxFX3H"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se está tudo correto com nosso dataset"
      ],
      "metadata": {
        "id": "WTCdIJesg12_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtém-se o tamanho do vocabulário"
      ],
      "metadata": {
        "id": "Sa4i8-vVOrp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(dataset.word_to_idx)\n",
        "print(f'O vocaculario possui {vocab_size} palavras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3JQ4zdfOrxW",
        "outputId": "97584665-ebbb-4f4f-868f-5d8341eab5c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O vocaculario possui 362 palavras\n",
            "O vocaculario possui 362 palavras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciando o modelo baseado em RNN"
      ],
      "metadata": {
        "id": "mCyYOsDfFdKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNModel(vocab_size+1, embedding_dim, hidden_dim, num_layers)"
      ],
      "metadata": {
        "id": "CvB2Zw24FdSW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Definindo a função de perda, em que a função softmax está implementada internamente:"
      ],
      "metadata": {
        "id": "SX_T2ji4Film"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Bsr90TBVFiuG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo-se o otimizador Adam"
      ],
      "metadata": {
        "id": "ZGelQn85Ft0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "hJUcGenNFt8u"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento da RNN\n",
        "\n",
        "\n",
        "\n",
        "1.   O treinamento é feito manualmente, pegando-se batch por batch\n",
        "2.   Primeiramente, pega-se os textos do batch sendo analisados e prepara-os para colocá-los no modelo\n",
        "3.   Inicializa $h^{(0)}$\n",
        "4.   Depois, calcula $h^{(t)}$\n",
        "5.   Após processar todas as palavras do texto de entrada, calcula-se a função loss\n",
        "6.   Atualiza os pesos da rede fazendo-se o backpropagation"
      ],
      "metadata": {
        "id": "01jD04pcFQwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "\n",
        "        tokens, labels = batch['input_ids'], batch['labels']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output,_ = model(tokens)\n",
        "\n",
        "        output_flat = output.view(-1, output.shape[-1])\n",
        "        labels_flat = labels.view(-1)\n",
        "\n",
        "        loss = loss_function(output_flat, labels_flat)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4QOsRZtFQ2P",
        "outputId": "a048ce4e-3d42-4014-a6f0-db8658750891"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 5.902366638183594\n",
            "Epoch 2, Loss: 5.850257555643718\n",
            "Epoch 3, Loss: 5.80612850189209\n",
            "Epoch 4, Loss: 5.762238105138143\n",
            "Epoch 5, Loss: 5.717470089594523\n",
            "Epoch 6, Loss: 5.6708824634552\n",
            "Epoch 7, Loss: 5.621278524398804\n",
            "Epoch 8, Loss: 5.566962560017903\n",
            "Epoch 9, Loss: 5.5057750542958575\n",
            "Epoch 10, Loss: 5.4366841316223145\n",
            "Epoch 11, Loss: 5.364171981811523\n",
            "Epoch 12, Loss: 5.2970796426137285\n",
            "Epoch 13, Loss: 5.2382363478342695\n",
            "Epoch 14, Loss: 5.1847489674886065\n",
            "Epoch 15, Loss: 5.13417402903239\n",
            "Epoch 16, Loss: 5.0859731038411455\n",
            "Epoch 17, Loss: 5.040077288945516\n",
            "Epoch 18, Loss: 4.99564266204834\n",
            "Epoch 19, Loss: 4.951560417811076\n",
            "Epoch 20, Loss: 4.907270431518555\n",
            "Epoch 21, Loss: 4.862528006235759\n",
            "Epoch 22, Loss: 4.8171153863271075\n",
            "Epoch 23, Loss: 4.77091646194458\n",
            "Epoch 24, Loss: 4.72383451461792\n",
            "Epoch 25, Loss: 4.675752401351929\n",
            "Epoch 26, Loss: 4.626632928848267\n",
            "Epoch 27, Loss: 4.576525529225667\n",
            "Epoch 28, Loss: 4.5255117019017534\n",
            "Epoch 29, Loss: 4.473669449488322\n",
            "Epoch 30, Loss: 4.421064138412476\n",
            "Epoch 31, Loss: 4.367770989735921\n",
            "Epoch 32, Loss: 4.313880205154419\n",
            "Epoch 33, Loss: 4.259478330612183\n",
            "Epoch 34, Loss: 4.204640746116638\n",
            "Epoch 35, Loss: 4.149434169133504\n",
            "Epoch 36, Loss: 4.093928615252177\n",
            "Epoch 37, Loss: 4.038192470868428\n",
            "Epoch 38, Loss: 3.982290426890055\n",
            "Epoch 39, Loss: 3.9262779156366983\n",
            "Epoch 40, Loss: 3.870208223660787\n",
            "Epoch 41, Loss: 3.8141295512517295\n",
            "Epoch 42, Loss: 3.7580856482187905\n",
            "Epoch 43, Loss: 3.7021135489145913\n",
            "Epoch 44, Loss: 3.6462478240331015\n",
            "Epoch 45, Loss: 3.5905171632766724\n",
            "Epoch 46, Loss: 3.534949779510498\n",
            "Epoch 47, Loss: 3.479569355646769\n",
            "Epoch 48, Loss: 3.4243977467219033\n",
            "Epoch 49, Loss: 3.369456092516581\n",
            "Epoch 50, Loss: 3.3147637049357095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predição"
      ],
      "metadata": {
        "id": "-rByT6SHHNC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, input_text):\n",
        "    input_text = input_text.split()\n",
        "    input_data = torch.tensor([[dataset.word_to_idx[word] for word in input_text]])\n",
        "    output, _ = model(input_data)\n",
        "    _, predicted_idx = torch.max(output[:, -1], 1)\n",
        "    predicted_word = dataset.idx_to_word[predicted_idx.item()]\n",
        "    return predicted_word"
      ],
      "metadata": {
        "id": "lr6EogyyHNKh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo o modelo de linguagem funcionar"
      ],
      "metadata": {
        "id": "guK025axHPmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"termo\"\n",
        "predicted_word = predict_next_word(model, input_text)\n",
        "print(f\"A proxima palavra apos {input_text} eh {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcKk23diHPtp",
        "outputId": "bfa3e2aa-d2e6-49f4-c2a6-71489131290e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A proxima palavra apos termo eh como\n"
          ]
        }
      ]
    }
  ]
}